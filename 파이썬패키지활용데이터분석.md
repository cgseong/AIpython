## 파이썬 패키지를 활용한 데이터 분석

**강의 목표:**

*   Pandas, Matplotlib, Seaborn 등 파이썬 패키지를 활용하여 실제 데이터를 분석하는 능력을 키웁니다.
*   다양한 데이터셋 (Iris, Titanic, 카페 판매 데이터, 세탁기 센서 데이터, 공공데이터)을 분석하며 데이터 분석 프로세스를 익힙니다.
*   데이터 시각화를 통해 데이터의 특성을 파악하고 의미 있는 정보를 도출할 수 있습니다.

---

### 1. 데이터 분석

**1.1. Iris 데이터 분석**

*   **데이터셋 설명:** Iris 데이터셋은 붓꽃의 종류 (Setosa, Versicolor, Virginica) 별로 꽃잎 길이 (sepal length), 꽃잎 너비 (sepal width), 꽃받침 길이 (petal length), 꽃받침 너비 (petal width)를 측정한 데이터입니다.
*   **분석 목표:** 각 붓꽃 종별 특징을 파악하고, 시각화를 통해 종별 차이를 비교 분석합니다.

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 데이터 로드
iris = pd.read_csv('iris.csv') # 또는 sklearn.datasets.load_iris() 사용 가능

# 데이터 기본 정보 확인
print(iris.info())
print(iris.head())
print(iris.describe())

# 종별 분포 확인
print(iris['species'].value_counts())

# 시각화 (Scatter Plot)
sns.scatterplot(x='sepal_length', y='sepal_width', hue='species', data=iris)
plt.title('Sepal Length vs Sepal Width by Species')
plt.show()

sns.scatterplot(x='petal_length', y='petal_width', hue='species', data=iris)
plt.title('Petal Length vs Petal Width by Species')
plt.show()

# 시각화 (Box Plot)
sns.boxplot(x='species', y='sepal_length', data=iris)
plt.title('Sepal Length by Species')
plt.show()

sns.boxplot(x='species', y='sepal_width', data=iris)
plt.title('Sepal Width by Species')
plt.show()

# 상관관계 분석 (Heatmap) - 숫자형 컬럼만 선택
numeric_iris = iris.select_dtypes(include=['number'])  # 숫자형 컬럼만 선택
correlation_matrix = numeric_iris.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix of Iris Features (Numeric Only)')
plt.show()
```

**1.2. Titanic 데이터 분석**

*   **데이터셋 설명:** Titanic 데이터셋은 타이타닉호 침몰 사고의 탑승객 정보를 담고 있습니다.  생존 여부 (Survived), 나이 (Age), 성별 (Sex), 티켓 등급 (Pclass), 동반 가족 수 (SibSp, Parch) 등의 정보를 포함합니다.
*   **분석 목표:** 생존에 영향을 미치는 요인을 분석하고, 생존율을 예측하는 모델을 개발합니다. (머신러닝 모델링은 다음 강의에서 다룹니다.)

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 데이터 로드
titanic = pd.read_csv('titanic.csv')

# 데이터 기본 정보 확인
print(titanic.info())
print(titanic.head())
print(titanic.describe())

# 결측치 처리 (Age)
titanic['age'] = titanic['age'].fillna(titanic['age'].mean())

# 범주형 변수 변환 (Sex)
titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})

# Embarked 결측치 처리 (최빈값으로 대체)
titanic['embarked'] = titanic['embarked'].fillna(titanic['embarked'].mode()[0])

# Embarked 인코딩 (One-Hot Encoding)
embarked_encoded = pd.get_dummies(titanic['embarked'], prefix='embarked')
titanic = pd.concat([titanic, embarked_encoded], axis=1)
titanic.drop('embarked', axis=1, inplace=True)

# 불필요한 컬럼 삭제 (name, ticket, cabin)
titanic.drop(['name', 'ticket', 'cabin'], axis=1, inplace=True)

# passengerid 컬럼은 분석에 의미가 없으므로 삭제
titanic.drop('passengerid', axis=1, inplace=True)

# 숫자형 컬럼만 선택
numeric_titanic = titanic.select_dtypes(include=['number'])

# 상관관계 분석 (Heatmap)
correlation_matrix = numeric_titanic.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix of Titanic Features (Numeric Only)')
plt.show()

# 생존율 분석
print(titanic['survived'].value_counts(normalize=True))

# 시각화 (Bar Plot)
sns.countplot(x='survived', data=titanic)
plt.title('Survival Count')
plt.show()

sns.countplot(x='pclass', hue='survived', data=titanic)
plt.title('Survival Count by Pclass')
plt.show()

sns.countplot(x='sex', hue='survived', data=titanic)
plt.title('Survival Count by Sex')
plt.show()

# 시각화 (Histogram)
sns.histplot(data=titanic, x='age', hue='survived', kde=True)
plt.title('Age Distribution by Survival')
plt.show()
```

**1.3. 카페 판매 데이터 분석**

*   **데이터셋 설명:** 카페에서 판매된 음료, 디저트 등의 판매 기록 데이터입니다.  날짜, 메뉴, 판매량, 가격 등의 정보를 포함합니다.
*   **분석 목표:** 가장 인기 있는 메뉴, 시간대별 판매 추이, 매출 분석 등을 수행합니다.

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 데이터 로드
cafe = pd.read_csv('cafe_sales.csv')

# 데이터 기본 정보 확인
print(cafe.info())
print(cafe.head())

# 날짜 형식 변환
cafe['date'] = pd.to_datetime(cafe['date'])

# 일별 총 판매량 계산
daily_sales = cafe.groupby('date')['sales'].sum()
print(daily_sales.head())

# 시각화 (Line Plot - 일별 판매 추이)
plt.plot(daily_sales.index, daily_sales.values)
plt.xlabel('Date')
plt.ylabel('Total Sales')
plt.title('Daily Sales Trend')
plt.xticks(rotation=45)  # x축 레이블 회전
plt.tight_layout()  # 레이아웃 조정
plt.show()

# 메뉴별 판매량 분석
menu_sales = cafe.groupby('menu')['sales'].sum().sort_values(ascending=False)
print(menu_sales.head())

# 시각화 (Bar Plot - 메뉴별 판매량)
plt.bar(menu_sales.index, menu_sales.values)
plt.xlabel('Menu')
plt.ylabel('Total Sales')
plt.title('Menu Sales')
plt.xticks(rotation=45, ha='right') # x축 레이블 회전 및 정렬
plt.tight_layout()
plt.show()

# 시간대별 판매량 분석 (새로운 시간대 컬럼 추가)
cafe['hour'] = cafe['date'].dt.hour # datetime에서 시간 추출
hourly_sales = cafe.groupby('hour')['sales'].sum()

# 시각화 (Line Plot - 시간대별 판매량)
plt.plot(hourly_sales.index, hourly_sales.values)
plt.xlabel('Hour')
plt.ylabel('Total Sales')
plt.title('Hourly Sales Trend')
plt.show()
```

**1.4. 세탁기 센서 데이터 분석**

*   **데이터셋 설명:** 세탁기의 작동 중 발생하는 센서 데이터입니다.  전류, 전압, 진동 등의 정보를 포함합니다.
*   **분석 목표:** 세탁기 작동 상태를 파악하고, 이상 감지 모델 개발을 위한 기초 분석을 수행합니다.

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 데이터 로드
laundry = pd.read_csv('laundry_sensor.csv')

# 데이터 기본 정보 확인
print(laundry.info())
print(laundry.head())

# 시계열 데이터로 변환 (date 컬럼을 datetime으로 변환하고 index로 설정)
laundry['date'] = pd.to_datetime(laundry['date'])
laundry = laundry.set_index('date')

# 시각화 (Line Plot - 전류, 전압, 진동 추이)
plt.figure(figsize=(12, 6))
plt.plot(laundry['current'], label='Current')
plt.plot(laundry['voltage'], label='Voltage')
plt.plot(laundry['vibration'], label='Vibration')
plt.xlabel('Date')
plt.ylabel('Value')
plt.title('Laundry Sensor Data')
plt.legend()
plt.show()

# 특정 기간 데이터 분석 (예: 특정 날짜 범위의 데이터만 선택)
start_date = '2023-01-01'
end_date = '2023-01-07'
laundry_subset = laundry[start_date:end_date] # 날짜 범위로 데이터 선택

# 선택된 기간의 데이터 시각화
plt.figure(figsize=(12, 6))
plt.plot(laundry_subset['current'], label='Current')
plt.xlabel('Date')
plt.ylabel('Current')
plt.title(f'Laundry Current Data ({start_date} to {end_date})')
plt.legend()
plt.show()

# 각 센서 값의 통계 정보 확인
print(laundry.describe())

# (선택 사항) 이상치 탐지 (예: IQR 기반)
Q1 = laundry['current'].quantile(0.25)
Q3 = laundry['current'].quantile(0.75)
IQR = Q3 - Q1
outliers = laundry[(laundry['current'] < (Q1 - 1.5 * IQR)) | (laundry['current'] > (Q3 + 1.5 * IQR))]
print("Outliers:")
print(outliers)
```

### 2. 공공데이터 분석

**사전 준비:**

*   [공공데이터포털](https://www.data.go.kr/)에 접속하여 필요한 데이터를 다운로드합니다.
*   각 데이터셋의 활용 목적과 특징을 파악합니다.

**2.1. 문화역세권 데이터 분석**

*   **데이터셋 설명:** 문화체육관광부에서 제공하는 문화역서울 284 관련 데이터
*   **분석 목표:** 지역별 문화 시설 분포 및 이용 현황 분석

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 데이터 로드 (데이터 파일명 및 경로 수정 필요)
culture_station = pd.read_csv('culture_station.csv', encoding='cp949')

# 데이터 기본 정보 확인
print(culture_station.info())
print(culture_station.head())

# 지역별 문화 시설 수 분석
region_counts = culture_station['지역'].value_counts()
print(region_counts)

# 시각화 (Bar Plot - 지역별 문화 시설 수)
plt.bar(region_counts.index, region_counts.values)
plt.xlabel('Region')
plt.ylabel('Number of Culture Facilities')
plt.title('Number of Culture Facilities by Region')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# (데이터에 따라) 시설 종류별 분석 등 추가 분석 수행
```

**2.2. 지역별 문화 시설 이용도 데이터 분석**

*   **데이터셋 설명:**  지역별 문화 시설 (공연장, 박물관, 미술관 등) 이용 현황 데이터
*   **분석 목표:**  지역별 문화 시설 이용률 비교, 인기 시설 유형 분석

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 데이터 로드 (데이터 파일명 및 경로 수정 필요)
culture_usage = pd.read_csv('culture_usage.csv', encoding='cp949')

# 데이터 기본 정보 확인
print(culture_usage.info())
print(culture_usage.head())

# 지역별 총 이용자 수 계산
region_usage = culture_usage.groupby('지역')['이용자수'].sum().sort_values(ascending=False)
print(region_usage)

# 시각화 (Bar Plot - 지역별 총 이용자 수)
plt.bar(region_usage.index, region_usage.values)
plt.xlabel('Region')
plt.ylabel('Total Number of Users')
plt.title('Total Number of Users by Region')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# (데이터에 따라) 시설 종류별 이용률 분석, 시간대별 이용 분석 등 추가 분석 수행
```

**2.3. 전국 공연 만족도 지도**

*   **데이터셋 설명:** 전국 공연에 대한 만족도 조사 데이터 (지역, 공연 종류, 만족도 점수 등)
*   **분석 목표:** 지역별 공연 만족도 수준 비교, 인기 공연 장르 분석 (지도는 Folium 등의 라이브러리 활용 필요)

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# Folium 은 다음 강의 또는 별도 강의에서 다룰 예정입니다.

# 데이터 로드 (데이터 파일명 및 경로 수정 필요)
performance_satisfaction = pd.read_csv('performance_satisfaction.csv', encoding='cp949')

# 데이터 기본 정보 확인
print(performance_satisfaction.info())
print(performance_satisfaction.head())

# 지역별 평균 만족도 계산
region_satisfaction = performance_satisfaction.groupby('지역')['만족도'].mean().sort_values(ascending=False)
print(region_satisfaction)

# 시각화 (Bar Plot - 지역별 평균 만족도)
plt.bar(region_satisfaction.index, region_satisfaction.values)
plt.xlabel('Region')
plt.ylabel('Average Satisfaction Score')
plt.title('Average Satisfaction Score by Region')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# (데이터에 따라) 공연 종류별 만족도 분석, 만족도에 영향을 미치는 요인 분석 등 추가 분석 수행
```

**2.4. 관광데이터 분석**

*   **데이터셋 설명:** 관광객 방문 데이터, 관광지 정보 데이터, 관광 관련 소비 데이터 등
*   **분석 목표:** 인기 관광지 분석, 관광객 소비 패턴 분석, 지역 관광 활성화 방안 제시

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 데이터 로드 (데이터 파일명 및 경로 수정 필요, 예시)
tourist_data = pd.read_csv('tourist_data.csv', encoding='cp949')

# 데이터 기본 정보 확인
print(tourist_data.info())
print(tourist_data.head())

# 인기 관광지 분석 (예시)
top_destinations = tourist_data['destination'].value_counts().nlargest(10)  # 방문객 수 기준 상위 10개 관광지
print(top_destinations)

# 시각화 (Bar Plot - 인기 관광지)
plt.bar(top_destinations.index, top_destinations.values)
plt.xlabel('Destination')
plt.ylabel('Number of Visitors')
plt.title('Top 10 Tourist Destinations')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# (데이터에 따라) 관광객 소비 패턴 분석, 연령별/성별 관광 트렌드 분석, 지역별 관광 활성화 방안 제시 등 추가 분석 수행
```

**2.5. 관광데이터 Word Cloud**

*   **데이터셋 설명:** 관광객 리뷰 데이터, 관광 관련 뉴스 기사 데이터 등 텍스트 데이터
*   **분석 목표:** 관광객들이 언급하는 주요 키워드 분석, 관광지에 대한 이미지 분석 (텍스트 데이터 전처리 및 WordCloud 라이브러리 활용 필요)

```python
import pandas as pd
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from konlpy.tag import Okt # 한국어 자연어 처리 라이브러리, 필요시 설치: pip install konlpy

# 텍스트 데이터가 있는 CSV 파일 로드 (데이터 파일명 및 경로 수정 필요)
review_data = pd.read_csv('tourist_reviews.csv', encoding='utf-8')

# 데이터 기본 정보 확인
print(review_data.info())
print(review_data.head())

# 텍스트 데이터 추출
reviews = ' '.join(review_data['review'].astype(str).tolist())

# 텍스트 데이터 전처리 (한국어 형태소 분석)
okt = Okt()
tokens = okt.nouns(reviews)  # 명사 추출

# 불용어 제거 (예: 조사, 접속사 등)
stopwords = ['있다', '하다', '되다', '이다', '없다', '그렇다', '않다', '것', '수', '등', '및', '가', '에', '을', '를', '은', '는', '이', '가'] # 예시, 불용어 목록은 필요에 따라 수정
tokens = [word for word in tokens if word not in stopwords]

# Word Cloud 생성
wordcloud = WordCloud(font_path='NanumGothic.ttf',  # 한글 폰트 지정 (NanumGothic 예시)
                      width=800,
                      height=400,
                      background_color='white').generate(' '.join(tokens))

# Word Cloud 시각화
plt.figure(figsize=(12, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off') # 축 숨기기
plt.title('Word Cloud of Tourist Reviews')
plt.show()
```

---

**다음 강의 예고:**

*   머신러닝 모델링 기초 (Scikit-learn)
*   모델 평가 및 성능 개선
*   AI 모델 배포 및 활용
